{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOvMtOc3l1yP0v1pOjx93et"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["5 State = {a, b, c, d, e}\n","\n","3 Actions = {Left, Right, Exit}\n","\n","Exit available only in a & e.\n","\n","Exit from a yields reward of 10\n","\n","Exit from e yields reward of 1\n","\n","(1) Calculate Optimum Policy for cases: Transitions are deterministic, ùõæ=1, ùõæ=0.1\n","\n","(2) Calculate the value of the sequence of rewards from each of the states under the optimum policy for both previous cases.\n","\n","(3) For which ùõæ, are West and East equally good when in state d?"],"metadata":{"id":"usEfyHA_e67h"}},{"cell_type":"code","source":["from math import sqrt as sq\n","\n","Rewards = [10, 0, 0, 0, 1]\n","\n","# Functions that calculate rewards on taking different actions (left or right)\n","Reward_left = lambda state, y: Rewards[state] if state <= 0 else Rewards[state] + y * Reward_left(state-1, y)\n","Reward_right = lambda state, y: Rewards[state] if state >= 4 else Rewards[state] + y * Reward_right(state+1, y)\n","\n","# Functions that compare which actions give better reward\n","def compare(state, y):\n","  if Reward_left(state, y) >= Reward_right(state, y):\n","    return \"Go left\"\n","  else:\n","    return \"Go right\""],"metadata":{"id":"RYw8FJEHN28g","executionInfo":{"status":"ok","timestamp":1725360388041,"user_tz":420,"elapsed":220,"user":{"displayName":"Chester Lee","userId":"08616585164992109780"}}},"execution_count":51,"outputs":[]},{"cell_type":"code","source":["# @title (1) Calculate Optimum Policy for cases: Transitions are deterministic, ùõæ=1, ùõæ=0.1\n","\n","# For ùõæ=1 case,\n","y = 1\n","print(\"y = 1\")\n","\n","# Since there is no discounting on the reward, the optimum policy for states b, c, and d will be going left(west) to obtain maximum reward of 10.\n","print(compare(1,y) + \" in state b\")\n","print(compare(2,y) + \" in state c\")\n","print(compare(3,y) + \" in state d\")\n","\n","#-------------------------------------------------------------------------------------------------------------------------------------------------------#\n","# For ùõæ=0.1 case,\n","y = 0.1\n","print(\"\\ny = 0.1\")\n","\n","# The optimum policy for states b and c are going left whereas it is better to go right for state d.\n","print(compare(1,y) + \" in state b\")\n","print(compare(2,y) + \" in state c\")\n","print(compare(3,y) + \" in state d\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nUEWd5fPe-jC","executionInfo":{"status":"ok","timestamp":1725360388273,"user_tz":420,"elapsed":6,"user":{"displayName":"Chester Lee","userId":"08616585164992109780"}},"outputId":"ea383cc8-6262-4183-b93d-562ec1717e80"},"execution_count":52,"outputs":[{"output_type":"stream","name":"stdout","text":["y = 1\n","Go left in state b\n","Go left in state c\n","Go left in state d\n","\n","y = 0.1\n","Go left in state b\n","Go left in state c\n","Go right in state d\n"]}]},{"cell_type":"code","source":["# @title (2) Calculate the value of the sequence of rewards from each of the states under the optimum policy for both previous cases.\n","\n","# For ùõæ=1 case,\n","y = 1\n","print(\"y = 1\")\n","\n","print(\"Reward for state b is \" + str(Reward_left(1,y)))\n","print(\"Reward for state c is \" + str(Reward_left(2,y)))\n","print(\"Reward for state d is \" + str(Reward_left(3,y)))\n","\n","#-------------------------------------------------------------------------------------------------------------------------------------------------------#\n","# For ùõæ=0.1 case,\n","y = 0.1\n","print(\"\\ny = 0.1\")\n","\n","print(\"Reward for state b is \" + str(Reward_left(1,y)))\n","print(\"Reward for state c is \" + str(Reward_left(2,y)))\n","print(\"Reward for state d is \" + str(Reward_right(3,y)))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MZGaCpvXMXC6","executionInfo":{"status":"ok","timestamp":1725360388274,"user_tz":420,"elapsed":6,"user":{"displayName":"Chester Lee","userId":"08616585164992109780"}},"outputId":"d6c6df3c-61f4-4aa4-e556-b328f3e80ee3"},"execution_count":53,"outputs":[{"output_type":"stream","name":"stdout","text":["y = 1\n","Reward for state b is 10\n","Reward for state c is 10\n","Reward for state d is 10\n","\n","y = 0.1\n","Reward for state b is 1.0\n","Reward for state c is 0.1\n","Reward for state d is 0.1\n"]}]},{"cell_type":"code","source":["# @title (3) For which ùõæ, are West and East equally good when in state d?\n","\n","# At state d,\n","# Reward left = Reward right\n","# 0 + y*0 + y^2*0 + y^3*10 = 0 + y*1\n","#                   y^3*10 = y*1\n","#                      y^2 = 1/10\n","#                        y = 1/sqrt(10)\n","\n","# Verify answer\n","y = 1 / sq(10)\n","print(y)\n","\n","print(\"Reward for going left is \" + str(Reward_left(3,y)))\n","print(\"Reward for going right is \" + str(Reward_right(3,y)))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Hfj5h6pKOzcE","executionInfo":{"status":"ok","timestamp":1725360388274,"user_tz":420,"elapsed":4,"user":{"displayName":"Chester Lee","userId":"08616585164992109780"}},"outputId":"281e9a27-254e-449b-a51e-59c161b6325b"},"execution_count":54,"outputs":[{"output_type":"stream","name":"stdout","text":["0.31622776601683794\n","Reward for going left is 0.31622776601683794\n","Reward for going right is 0.31622776601683794\n"]}]}]}